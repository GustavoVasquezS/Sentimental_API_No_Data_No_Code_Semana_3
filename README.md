# ğŸ¯ SentimentAPI v3.0 - AnÃ¡lisis de Sentimientos en EspaÃ±ol

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)](https://scikit-learn.org/)

## ğŸ“‹ DescripciÃ³n del Proyecto

**SentimentAPI** es una soluciÃ³n completa de Machine Learning para el anÃ¡lisis de sentimientos de reseÃ±as de Amazon en espaÃ±ol. El sistema recibe textos y devuelve una clasificaciÃ³n de sentimiento con probabilidad calibrada y flag de revisiÃ³n humana.

### Clasificaciones disponibles:
- ğŸŸ¢ **Positivo** (estrellas 4-5)
- ğŸŸ¡ **Neutro** (estrella 3)
- ğŸ”´ **Negativo** (estrellas 1-2)

### CaracterÃ­sticas principales:
- âœ… Probabilidad calibrada (0-1) interpretable
- âœ… Flag `review_required` para casos de baja confianza (<60%)
- âœ… Trazabilidad con versiÃ³n del modelo y hash
- âœ… Endpoint batch para mÃºltiples textos (hasta 100)
- âœ… Bundle Ãºnico (`sentiment_bundle.joblib`) listo para producciÃ³n

---

## ğŸ“Š MÃ©tricas del Modelo

| MÃ©trica | Test Set |
|:--------|:--------:|
| **Accuracy** | 77.54% |
| **F1-macro** | 68.62% |
| **Recall Negativo** | 90.4% |
| **Recall Positivo** | 89.95% |

### Classification Report (Test)

```
              precision    recall  f1-score   support

    Negativo       0.78      0.90      0.84      2000
      Neutro       0.57      0.27      0.37      1000
    Positivo       0.81      0.90      0.85      2000

    accuracy                           0.78      5000
   macro avg       0.72      0.69      0.69      5000
weighted avg       0.75      0.78      0.75      5000
```

### Matriz de ConfusiÃ³n

|  | Negativo | Neutro | Positivo |
|:--|:--:|:--:|:--:|
| **Negativo** | 1808 | 109 | 83 |
| **Neutro** | 399 | 270 | 331 |
| **Positivo** | 104 | 97 | 1799 |

> ğŸ“ **Nota:** El modelo prioriza alto recall en Negativo (90.4%) para no perder crÃ­ticas importantes en atenciÃ³n al cliente.

---

## ï¿½ Archivos Grandes (Descarga Requerida)

Los siguientes archivos superan el lÃ­mite de GitHub y deben descargarse manualmente:

| Archivo | DescripciÃ³n | 
|---------|-------------|
| `train.csv` | Dataset de entrenamiento (~200K reseÃ±as de Amazon multilenguaje) |
| `sentiment_bundle.joblib` | Modelo ML serializado (pipeline completo + metadata) |

ğŸ“ **Descargar desde:** [Google Drive](https://drive.google.com/file/d/18Hd2lqwTytVHA7I5lbjQ6YzKWQ34ok36/view?usp=sharing)

> âš ï¸ **Importante:** Coloca ambos archivos en la raÃ­z del proyecto antes de ejecutar el notebook o la API.

---

## ğŸš€ Inicio RÃ¡pido

### 1. Descargar archivos grandes
Descarga `train.csv` y `sentiment_bundle.joblib` desde el [enlace de Google Drive](https://drive.google.com/file/d/18Hd2lqwTytVHA7I5lbjQ6YzKWQ34ok36/view?usp=sharing) y colÃ³calos en la raÃ­z del proyecto.

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Ejecutar el notebook para entrenar el modelo
```bash
jupyter notebook Proyecto_final_v8.ipynb
# Ejecutar todas las celdas para generar sentiment_bundle.joblib
```

### 3. Iniciar la API
```bash
cd api
uvicorn main:app --reload --port 8000
```

### 4. Probar la API
```bash
# Health check
curl http://localhost:8000/health

# AnÃ¡lisis de sentimiento
curl -X POST "http://localhost:8000/sentiment" \
     -H "Content-Type: application/json" \
     -d '{"text": "El producto es excelente y llegÃ³ rÃ¡pido"}'
```

### 5. DocumentaciÃ³n interactiva
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ—ï¸ Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SentimentAPI v3.0                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ğŸ“Š Data Science    â”‚         â”‚      ğŸ API (FastAPI)        â”‚ â”‚
â”‚  â”‚     (Notebook)       â”‚         â”‚                              â”‚ â”‚
â”‚  â”‚                      â”‚         â”‚  â€¢ POST /sentiment           â”‚ â”‚
â”‚  â”‚  â€¢ EDA               â”‚  â”€â”€â”€â”€â–º  â”‚  â€¢ POST /sentiment/batch     â”‚ â”‚
â”‚  â”‚  â€¢ Preprocesamiento  â”‚         â”‚  â€¢ GET /health               â”‚ â”‚
â”‚  â”‚  â€¢ TF-IDF            â”‚         â”‚  â€¢ GET /stats                â”‚ â”‚
â”‚  â”‚  â€¢ Logistic Regr.    â”‚         â”‚  â€¢ review_required flag      â”‚ â”‚
â”‚  â”‚  â€¢ CalibraciÃ³n       â”‚         â”‚  â€¢ Swagger UI                â”‚ â”‚
â”‚  â”‚  â€¢ Bundle joblib     â”‚         â”‚                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline de ML

```
Texto â†’ TextCleaner â†’ TF-IDF Vectorizer â†’ Logistic Regression (Calibrada) â†’ PredicciÃ³n
```

**Componentes:**

1. **TextCleaner**: lowercase, eliminaciÃ³n de URLs/menciones/hashtags, conservaciÃ³n de caracteres espaÃ±oles
2. **TF-IDF Vectorizer**: ngram_range=(1,2), min_df=3, max_df=0.95, max_features=200,000
3. **Logistic Regression**: solver=lbfgs, class_weight=balanced, C=1.0
4. **CalibraciÃ³n**: CalibratedClassifierCV con mÃ©todo sigmoid (3 folds)

---

## ğŸ“ Estructura del Proyecto

```
ğŸ“¦ No Country/
â”œâ”€â”€ ğŸ““ Proyecto_final_v8.ipynb     # Notebook principal (MVP Final)
â”œâ”€â”€ ğŸ“¦ sentiment_bundle.joblib     # Bundle del modelo (pipeline + metadata)
â”œâ”€â”€ ğŸ“Š train.csv                   # Dataset de entrenamiento (200K es)
â”œâ”€â”€ ğŸ“Š validation.csv              # Dataset de validaciÃ³n (5K es)
â”œâ”€â”€ ğŸ“Š test.csv                    # Dataset de test (5K es)
â”œâ”€â”€ ğŸ“„ README.md                   # Esta documentaciÃ³n
â”œâ”€â”€ ğŸ“„ requirements.txt            # Dependencias Python
â””â”€â”€ ğŸ“ api/
    â””â”€â”€ main.py                    # API FastAPI v3.0
```

---

## ğŸ”Œ API Endpoints

### POST /sentiment
Analiza el sentimiento de un texto.

**Request:**
```json
{
  "text": "El producto es excelente y llegÃ³ rÃ¡pido, muy recomendado."
}
```

**Response:**
```json
{
  "prevision": "Positivo",
  "probabilidad": 0.9249,
  "review_required": false,
  "threshold": 0.6,
  "model_version": "sentiment_es_tfidf_lr_calibrated_v1",
  "artifact_hash": "1c13b982c169"
}
```

### POST /sentiment/batch
Analiza mÃºltiples textos en una sola peticiÃ³n (mÃ¡x 100).

**Request:**
```json
{
  "texts": [
    "Excelente producto",
    "No funciona, llegÃ³ roto",
    "EstÃ¡ bien, cumple"
  ]
}
```

### GET /health
Verifica el estado de la API y del modelo.

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_version": "sentiment_es_tfidf_lr_calibrated_v1",
  "threshold": 0.6,
  "labels": ["Negativo", "Neutro", "Positivo"],
  "artifact_hash": "1c13b982c169"
}
```

### GET /stats
Obtiene estadÃ­sticas de uso.

**Response:**
```json
{
  "total_requests": 150,
  "positive_count": 95,
  "negative_count": 40,
  "neutral_count": 15,
  "review_required_count": 25,
  "review_required_percentage": 16.67,
  "avg_probability": 0.7823,
  "start_time": "2026-01-08T10:30:00"
}
```

### Campos de respuesta `/sentiment`

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| `prevision` | string | Clase predicha: "Negativo", "Neutro", "Positivo" |
| `probabilidad` | float | Confianza del modelo (0.0 - 1.0) |
| `review_required` | bool | `true` si probabilidad < threshold |
| `threshold` | float | Umbral de confianza (0.6) |
| `model_version` | string | VersiÃ³n del modelo |
| `artifact_hash` | string | Hash SHA256 del artefacto (12 chars) |

---

## ğŸ““ Notebook: Pipeline Completo

El notebook `Proyecto_final_v8.ipynb` estÃ¡ organizado en **14 secciones**:

| SecciÃ³n | Contenido |
|---------|-----------|
| **0-2** | Setup, carga de datos, EDA rÃ¡pida |
| **3** | PreparaciÃ³n de texto y labels (stars â†’ sentiment) |
| **4** | Baseline TF-IDF + Logistic Regression |
| **5** | OptimizaciÃ³n con GridSearchCV (CV estratificada) |
| **6** | CalibraciÃ³n de probabilidades (sigmoid) |
| **7** | PolÃ­tica de revisiÃ³n (`review_required`) |
| **8** | EvaluaciÃ³n final en test holdout |
| **9** | Explicabilidad (tÃ©rminos influyentes por clase) |
| **10** | SerializaciÃ³n productiva (bundle joblib) |
| **11** | Funciones para Back-End (`validate_text`, `predict_one`) |
| **12-14** | Contrato API, ejemplos cURL, notas de producciÃ³n |

### TÃ©rminos mÃ¡s influyentes por clase

| Clase | TÃ©rminos Positivos | TÃ©rminos Negativos |
|-------|-------------------|-------------------|
| **Negativo** | no, mala, no funciona, fatal, decepciÃ³n, roto | perfecto, buena, genial, excelente, bien |
| **Neutro** | pero, tres estrellas, regular, aceptable, mejorable | excelente, recomiendo, perfecto, genial |
| **Positivo** | perfecto, genial, excelente, encantado, recomendable | no, mala, regular, no funciona, mal |

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Data Science (Notebook)
| TecnologÃ­a | Uso |
|------------|-----|
| ğŸ Python 3.10+ | Lenguaje principal |
| ğŸ“Š Pandas, NumPy | ManipulaciÃ³n de datos |
| ğŸ“ˆ Matplotlib, Seaborn | Visualizaciones |
| ğŸ¤– scikit-learn | Modelo ML (TF-IDF + LogReg + CalibraciÃ³n) |
| ğŸ’¾ joblib | SerializaciÃ³n del modelo |

### API (ProducciÃ³n)
| TecnologÃ­a | Uso |
|------------|-----|
| âš¡ FastAPI | Framework web REST |
| ğŸ“ Pydantic | ValidaciÃ³n de datos |
| ğŸ”„ Uvicorn | Servidor ASGI |

---

## ğŸ“Š Ejemplos de Uso

### Python
```python
import requests

response = requests.post(
    "http://localhost:8000/sentiment",
    json={"text": "El producto es excelente y llegÃ³ rÃ¡pido"}
)
result = response.json()
print(f"Sentimiento: {result['prevision']}")
print(f"Confianza: {result['probabilidad']:.2%}")
print(f"Requiere revisiÃ³n: {result['review_required']}")
```

### cURL
```bash
# Positivo
curl -X POST "http://localhost:8000/sentiment" \
     -H "Content-Type: application/json" \
     -d '{"text": "El producto es excelente, llegÃ³ rÃ¡pido y funciona perfecto."}'

# Negativo
curl -X POST "http://localhost:8000/sentiment" \
     -H "Content-Type: application/json" \
     -d '{"text": "LlegÃ³ roto, pÃ©simo servicio y nadie responde."}'

# Neutro
curl -X POST "http://localhost:8000/sentiment" \
     -H "Content-Type: application/json" \
     -d '{"text": "EstÃ¡ bien, cumple lo prometido, nada especial."}'

# Batch
curl -X POST "http://localhost:8000/sentiment/batch" \
     -H "Content-Type: application/json" \
     -d '{"texts": ["Excelente", "Malo", "Normal"]}'
```

### JavaScript (fetch)
```javascript
const response = await fetch('http://localhost:8000/sentiment', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({text: 'EstÃ¡ bien, cumple lo prometido'})
});
const data = await response.json();
console.log(data.prevision);        // "Neutro"
console.log(data.review_required);  // true (baja confianza)
```

### Cargar el modelo directamente en Python
```python
import joblib
import numpy as np

# Cargar el bundle
bundle = joblib.load("sentiment_bundle.joblib")
pipeline = bundle["pipeline"]
meta = bundle["meta"]

# Predecir
text = "El producto es excelente"
proba = pipeline.predict_proba([text])[0]
pred = pipeline.classes_[np.argmax(proba)]
print(f"Sentimiento: {pred}, Confianza: {max(proba):.2%}")
```

---

## ğŸ¯ Casos de Uso

| Ãrea | AplicaciÃ³n |
|------|------------|
| ğŸ“ **AtenciÃ³n al Cliente** | ClasificaciÃ³n automÃ¡tica de tickets y priorizaciÃ³n |
| ğŸ“ˆ **Marketing** | AnÃ¡lisis de campaÃ±as y percepciÃ³n de marca |
| ğŸ“Š **Monitoreo** | Dashboard de sentimientos en tiempo real |
| ğŸ›’ **E-commerce** | AnÃ¡lisis de reseÃ±as de productos |
| ğŸ“± **Redes Sociales** | Monitoreo de menciones y tweets |

---

## ğŸš€ Despliegue

### Local
```bash
# Instalar dependencias
pip install -r requirements.txt

# Ejecutar notebook para entrenar modelo (genera sentiment_bundle.joblib)
jupyter notebook Proyecto_final_v8.ipynb

# Ejecutar API
cd api
uvicorn main:app --reload --port 8000
```

### Docker (Opcional)
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY sentiment_bundle.joblib .
COPY api/ ./api/
EXPOSE 8000
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
docker build -t sentiment-api .
docker run -p 8000:8000 sentiment-api
```

---

## ğŸ“Œ Notas de ProducciÃ³n

### Ventajas del enfoque

| Aspecto | Beneficio |
|---------|-----------|
| **Eficiencia** | TF-IDF + LR es rÃ¡pido y CPU-friendly |
| **Escalabilidad** | Modelo ligero, se carga una vez al iniciar |
| **Probabilidad confiable** | CalibraciÃ³n sigmoid mejora interpretaciÃ³n |
| **Robustez operacional** | `review_required` deriva casos dudosos a humanos |
| **Reproducibilidad** | Semilla fija + metadata con versiÃ³n y hash |
| **IntegraciÃ³n simple** | Un solo archivo `.joblib` contiene todo |

### Limitaciones conocidas

- **Clase Neutro**: Menor precisiÃ³n (57%) y recall (27%) â€” tÃ­pico en clasificaciÃ³n ternaria
- **Idioma**: Solo espaÃ±ol (filtrado por `language == "es"`)
- **Longitud**: Textos entre 5 y 2000 caracteres

### Recomendaciones

1. **Monitoreo**: Trackear % de `review_required` en producciÃ³n
2. **Feedback loop**: Usar casos revisados para re-entrenar
3. **Umbral ajustable**: Modificar `threshold` segÃºn tolerancia al riesgo
4. **Cache**: Considerar cache para textos repetidos

---

## âœ… Funcionalidades Implementadas

- [x] Notebook completo con EDA, preprocesamiento y entrenamiento
- [x] ClasificaciÃ³n ternaria (Positivo, Neutro, Negativo)
- [x] Modelo calibrado con probabilidades interpretables
- [x] Flag `review_required` para revisiÃ³n humana
- [x] Endpoint POST /sentiment con clasificaciÃ³n y probabilidad
- [x] Endpoint POST /sentiment/batch para mÃºltiples textos
- [x] Bundle Ãºnico (pipeline + metadata) en joblib
- [x] ValidaciÃ³n de input (5-2000 caracteres)
- [x] Trazabilidad (model_version, artifact_hash)
- [x] Endpoint GET /health con info del modelo
- [x] Endpoint GET /stats para estadÃ­sticas
- [x] DocumentaciÃ³n Swagger automÃ¡tica

## ğŸ”® Funcionalidades Opcionales (Para Extender)

- [ ] Persistencia en base de datos (PostgreSQL)
- [ ] Interfaz web con Streamlit
- [ ] Explicabilidad (top features por predicciÃ³n)
- [ ] ContenerizaciÃ³n completa con docker-compose
- [ ] Tests automatizados con pytest
- [ ] Ajuste dinÃ¡mico de threshold

---

## ğŸ‘¥ Equipo

Proyecto desarrollado por **"No Data - No Code"** en el marco del HackatÃ³n **No Country** ğŸŒ

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT.

---

<p align="center">
  <i>ğŸ’¡ Transformando feedback en insights accionables</i>
</p>

